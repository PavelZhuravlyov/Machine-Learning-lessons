{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import pymorphy2\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import gensim\n",
    "import re\n",
    "import pymystem3\n",
    "import functools\n",
    "import collections\n",
    "import itertools\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# In[3]:\n",
    "\n",
    "mystem = pymystem3.Mystem()\n",
    "\n",
    "def clear_string(word):\n",
    "    return re.sub(r'[^\\w\\s]', '', word)\n",
    "\n",
    "\n",
    "STOP_POS = frozenset([\n",
    "    'PREP', 'CONJ', 'PRCL',\n",
    "    'INTJ', 'NPRO', 'PRED',\n",
    "    'ADJF',\n",
    "])\n",
    "\n",
    "\n",
    "# Список слов, которые заменяются на \"Мужское имя\"\n",
    "BOYS_NAME_LIST = frozenset(\n",
    "    ['Абрам', 'Август', 'Авдей', 'Аверкий', 'Авксентий', 'Авраам', 'Автоном', 'Агап', 'Агафон', 'Аггей', 'Агей',\n",
    "     'Адам', 'Адольф', 'Адриан', 'Азарий', 'Аким', 'Александр', 'Александр', 'Алексей', 'Алексей', 'Альберт',\n",
    "     'Альтаир', 'Альфред', 'Амвросий', 'Амос', 'Ананий', 'Анатолий', 'Анатолий', 'Андрей', 'Андрей', 'Андриан',\n",
    "     'Андрон', 'Андроник', 'Аникей', 'Аникита', 'Анисим', 'Антип', 'Антон', 'Антонин', 'Аполлинарий',\n",
    "     'Аполлон', 'Арефий', 'Аристарх', 'Аркадий', 'Аркадий', 'Арсен', 'Арсен', 'Арсений', 'Арсений', 'Арсений',\n",
    "     'Артем', 'Артем', 'Артемий', 'Артемий', 'Артур', 'Артём', 'Архип', 'Архип', 'Аскольд', 'Афанасий', 'Афиноген',\n",
    "     'Бажен', 'Бенедикт', 'Богдан', 'Богдан', 'Болеслав', 'Болеслав', 'Бонифаций', 'Борис', 'Борис', 'Борислав',\n",
    "     'Боян', 'Бронислав', 'Бронислав', 'Будимир', 'Вадим', 'Вадим', 'Вадим', 'Валентин', 'Валентин', 'Валентин',\n",
    "     'Валерий', 'Валерий', 'Валерий', 'Валерьян', 'Валерьян', 'Вальтер', 'Варлаам', 'Варлаам', 'Варлам', 'Варлам',\n",
    "     'Варфоломей', 'Варфоломей', 'Василий', 'Василий', 'Василий', 'Василиск', 'Василиск', 'Велимир', 'Велимир',\n",
    "     'Венедикт', 'Венедикт', 'Вениамин', 'Вениамин', 'Вениамин', 'Викентий', 'Викентий', 'Виктор', 'Виктор',\n",
    "     'Виктор', 'Викторин', 'Викторин', 'Вильгельм', 'Виссарион', 'Виссарион', 'Виталий', 'Виталий', 'Виталий',\n",
    "     'Владилен', 'Владилен', 'Владимир', 'Владимир', 'Владимир', 'Владислав', 'Владислав', 'Владислав', 'Владлен',\n",
    "     'Владлен', 'Влас', 'Влас', 'Влас', 'Вольдемар', 'Всеволод', 'Всеволод', 'Всеволод', 'Всемил', 'Всемил',\n",
    "     'Всеслав', 'Всеслав', 'Вышеслав', 'Вышеслав', 'Вячеслав', 'Вячеслав', 'Вячеслав', 'Гавриил', 'Гавриил',\n",
    "     'Гаврила', 'Галактион', 'Гамлет', 'Гарри', 'Гедеон', 'Геннадий', 'Геннадий', 'Генрих', 'Георгий', 'Георгий',\n",
    "     'Георгий', 'Егор', 'Герасим', 'Герман', 'Герман', 'Глеб', 'Глеб', 'Гордей', 'Гордей', 'Гостомысл', 'Гремислав',\n",
    "     'Григорий', 'Григорий', 'Гурий', 'Давид', 'Давид', 'Давыд', 'Давыд', 'Давид', 'Даниил', 'Даниил', 'Даниил',\n",
    "     'Данила', 'Дементий', 'Демид', 'Демьян', 'Демьян', 'Денис', 'Денис', 'Дмитрий', 'Дмитрий', 'Добромысл',\n",
    "     'Доброслав', 'Донат', 'Дорофей', 'Евгений', 'Евгений', 'Евграф', 'Евдоким', 'Евдоким', 'Евлампий',\n",
    "     'Евлампий', 'Евсей', 'Евстафий', 'Евстигней', 'Егор', 'Егор', 'Елизар', 'Елисей', 'Елисей', 'Емельян',\n",
    "     'Епифан', 'Еремей', 'Ермил', 'Ермолай', 'Ерофей', 'Ефим', 'Ефим', 'Ефрем', 'Ефрем', 'Ждан', 'Захар',\n",
    "     'Зиновий', 'Иван', 'Иван', 'Игнат', 'Игнатий', 'Игнатий', 'Игорь', 'Игорь', 'Измаил', 'Изот',\n",
    "     'Изяслав', 'Иларион', 'Илларион', 'Илья', 'Илья', 'Иннокентий', 'Иннокентий', 'Иоан', 'Иосиф', 'Иосиф',\n",
    "     'Осип', 'Ипат', 'Ипатий', 'Ипполит', 'Ипполит', 'Ираклий', 'Исаак', 'Исаакий', 'Исаакий', 'Исай',\n",
    "     'Исидор', 'Карл', 'Карэн', 'Кирил', 'Кирилл', 'Кондрат', 'Константин', 'Кристиан', 'Лавр', 'Лаврентий',\n",
    "     'Лаврентий', 'Ладимир', 'Лазарь', 'Лев', 'Лев', 'Леон', 'Леонард', 'Леонид', 'Леонид', 'Леонтий',\n",
    "     'Леонтий', 'Лонгин', 'Лука', 'Лукьян', 'Лучезар', 'Любим', 'Любомир', 'Любомысл', 'Людвиг', 'Макар',\n",
    "     'Макар', 'Максим', 'Максим', 'Максимилиан', 'Максимилиан', 'Максимильян', 'Мануил', 'Марат', 'Мариан',\n",
    "     'Марк', 'Марк', 'Мартин(Мартын)', 'Мартын', 'Мартьян', 'Матвей', 'Матвей', 'Мефодий', 'Мечислав',\n",
    "     'Милан', 'Милен', 'Милий', 'Мина', 'Мир', 'Мирон', 'Мирон', 'Мирослав', 'Мирослав', 'Митрофан',\n",
    "     'Михаил', 'Михей', 'Модест', 'Моисей', 'Моисей', 'Мокей', 'Мстислав', 'Назар', 'Наркис',\n",
    "     'Натан', 'Наум', 'Нестер', 'Нестор', 'Никандр', 'Никанор', 'Никита', 'Никифор', 'Никодим', 'Никола',\n",
    "     'Николай', 'Никон', 'Нил', 'Нифонт', 'Овидий', 'Олег', 'Олесь', 'Онисим', 'Онисим', 'Осип', 'Оскар',\n",
    "     'Остап', 'Павел', 'Панкрат', 'Панкратий', 'Пантелей', 'Пантелеймон', 'Панфил', 'Парамон', 'Парфен',\n",
    "     'Парфений', 'Пахом', 'Петр', 'Пимен', 'Платон', 'Поликарп', 'Порфирий', 'Потап', 'Пров', 'Прокл',\n",
    "     'Прокоп', 'Прокопий', 'Прокофий', 'Прохор', 'Радик', 'Радим', 'Радислав', 'Радован',\n",
    "     'Ратибор', 'Ратмир', 'Рафаил', 'Рафаэль', 'Рафик', 'Ринат', 'Ричард', 'Роберт', 'Родион',\n",
    "     'Рома', 'Роман', 'Роман', 'Ростислав', 'Ростислав', 'Рудольф', 'Руслан', 'Руслан', 'Рустам', 'Рюрик',\n",
    "     'Савелий', 'Самуил', 'Святослав', 'Семен', 'Серафим', 'Сергей', 'Спартак', 'Спиридон', 'Станислав',\n",
    "     'Степан', 'Тамирлан', 'Тарас', 'Тарас', 'Твердислав', 'Творимир', 'Теодор', 'Терентий', 'Терентий',\n",
    "     'Тигран', 'Тимофей', 'Тимофей', 'Тимур', 'Тимур', 'Тит', 'Тихон', 'Тихон', 'Трифон', 'Трофим', 'Трофим',\n",
    "     'Ульян', 'Устин', 'Фадей', 'Фарид', \"Федя\", 'Федор', 'Федор', 'Федосей', 'Федосий', 'Федот', 'Феликс', 'Феликс',\n",
    "     'Феодосий', 'Феоктист', 'Феофан', 'Феофан', 'Ферапонт', 'Филимон', 'Филип', 'Филипп', 'Филипп', 'Фирс',\n",
    "     'Флор', 'Флорентин', 'Фока', 'Фома', 'Фома', 'Фортунат', 'Фотий', 'Фридрих', 'Фрол', 'Фёдор', 'Харитон',\n",
    "     'Харлампий', 'Христофор', 'Эдвард', 'Эдгар', 'Эдуард', 'Эльдар', 'Эмиль', 'Эрик', 'Эрнест', 'Ювеналий',\n",
    "     'Юджин', 'Юлиан', 'Юлиан', 'Юлий', 'Юлий', 'Юрий', 'Юрий', 'Юхим', 'Яков', 'Ян', 'Янус', 'Ярослав',\n",
    "     'Саша', 'Ганс','Макс','Максим', \"Алекс\", \"Тони\", \"Эрчин\", \"Вейд\", \"Лавини\", \"Димитро\", \"Иссей\", \"Рольф\",\n",
    "     \"Василя\", \"Зак\", \"Грэм\", \"Моргот\", \"Лиам\", \"Яго\", \"Эдди\", \"Мануйл\", \"Амери\", \"Митя\", \"Мати\", \"Дима\", \"Семён\", \"Алик\",\n",
    "     \"Пётр\", \"Яша\", \"Игар\", \"Пашка\", \"Гаррик\", \"Чарли\", \"Димка\", \"Лёня\", \"Аксен\", \"Анастасий\", \"Джон\", \"Эштон\", \"Питер\",\n",
    "      \"Сурен\", \"Бруно\",\"Ален\",\"Умарь\",\"Ярго\",\"Марель\", \"Азар\",\"Рик\", \"Хелена\", \"Рашид\", \"Рикардо\", \"Дориан\",\"Вейд\",\"Вэйд\",\n",
    "      \"Аят\", \"Панголин\", \"Исраил\", \"Амадей\", \"Джо\", \"Мэтью\", \"Браун\", \"Маркус\",\n",
    "      \"Джимми\", \"Джим\", \"Джеймс\", \"Юджин\", \"Грэга\", \"Грэг\",\"Морис\", \"Рэм\", \"Никс\", \"Колька\", \"Влад\", \"Вася\",\n",
    "      \"Жек\",\"Жека\", \"Ваня\", \"Ванька\", \"Анри\", \"Стоун\", \"Ванечка\", \"Анджело\", \"Грейс\", \"Ван\", \"Вани\", \"Факундо\",\n",
    "        \"Ванюша\", \"Армин\", \"Ленард\", \"Дениэл\", \"Дэниэл\", \"Киан\",\"Борман\", \"Ахмет\", \"Джош\", \"Тихвин\", \"Грег\",\n",
    "     \"Алан\", \"Патрик\", \"Жак\", \"Смит\", \"Мигель\", \"Фрост\", \"Джина\", \"Раяна\", \"Лекс\", \"Эрих\", \"Раф\", \"Павло\", \"Пабло\",\n",
    "     \"Стив\", \"Билл\", \"Бенедикто\", \"Доминик\", \"Билль\", \"Мэгга\", \"Вовчик\", \"Амариллис\", \"Родик\", \"Бим\", \"Аландо\", \"Жан\",\n",
    "     \"Сильвестр\", \"Роланд\", \"Володя\", \"Себастьян\", \"Виталик\", \"Ромка\", \"Казимир\", \"Себастьян\", \"Вовик\", \"Мэт\",\n",
    "     \"Гришка\", \"Гриша\", \"Бен\", \"Бэн\", \"Ленька\", \"Лёнька\", \"Зуев\", \"Малик\", \"Антоша\", \"Семёнов\", \"Мичурин\", \"Джеки\"\n",
    "     \"Джек\", \"Кай\", \"Савва\", \"Тимоха\", \"Жерар\", \"Рихард\", \"Василий\", \"Мотя\", \"Джастин\", \"Василёк\", \"Прокофьев\",\n",
    "     \"Илюшка\", \"Толика\", \"Витя\", \"Георг\", \"Вит\", \"Фред\", \"Волан\", \"Роберто\", \"Ромэо\", \"Ромео\", \"Джесси\", \"Рюг\", \"Раймонд\",\n",
    "     \"Гаспар\", \"Киса\", \"Алексий\", \"Армель\", \"Тимофеев\", \"Карло\", \"Гущин\", \"Тео\", \"Лёшка\", \"Изар\", \"Джалал\", \"Брюсов\", \"Афоня\",\n",
    "     \"Гоша\", \"Димона\", \"Димон\", \"Эйтан\", \"Юрик\", \"Паша\", \"Славик\", \"Дамир\", \"Савченко\", \"Филя\", \"Колин\", \"Рудаков\", \"Тайлера\",\n",
    "     \"Саид\", \"Иса\", \"Мурад\", \"Венцель\", \"Юсуф\", \"Симеон\", \"Лорик\", \"Гонорий\", \"Хайк\", \"Исмаил\", \"Мустафа\", \"Голованов\",\n",
    "     \"Йося\", \"Гилберт\", \"Рон\", \"Майк\", \"Алистер\", \"Антонов\", \"Лёва\", \"Михаэль\", \"Камил\", \"Ланс\", \"Богров\", \"Илюха\", \"Алек\",\n",
    "     \"Сережа\", \"Митька\", \"Тишка\", \"Стаст\", \"Анфис\", \"Романов\", \"Галар\", \"Николя\", \"Эван\", \"Фокс\", \"Коул\", \"Ирвин\",\n",
    "     \"Макфлай\", \"Уэйн\", \"Стивен\", \"Томас\", \"Ден\", \"Уильям\", \"Андрэ\", \"Мусин\", \"Кузя\", \"Крамер\", \"Джейк\", \"Хант\", \"Джеффри\",\n",
    "     \"Алексашка\", \"Мэддисон\", \"Сашка\", \"Фил\", \"Кейн\", \"Арчибальд\", \"Тимка\", \"Чоу\", \"Эрклион\", \"Коля\", \"Валерка\", \"Коляна\",\n",
    "     \"Колян\", \"Вадик\", \"Брайан\", \"Арик\", \"Хасан\", \"Ларионов\", \"Фима\", \"Прохоров\", \"Волошка\", \"Мурза\", \"Трунов\", \"Левушка\",\n",
    "     \"Валя\", \"Вале\", \"Валей\", \"Валюш\", \"Валер\", \"Валера\", \"Валерий\", \"Лидий\", \"Сергеев\", \"Эраст\", \"Ашот\", \"Лёшик\",\n",
    "     \"Хенрик\", \"Браун\", \"Данил\", \"Рабби\", \"Росс\", \"Самсон\", \"Антуан\", \"Фомин\", \"Фадеев\", \"Авгур\", \"Пластун\", \"Скобелев\",\n",
    "     \"Фролов\", \"Сирин\", \"Ахмед\", \"Вартан\", \"Болотов\", \"Лопухин\", \"Фет\", \"Марков\", \"Александэр\", \"Лаптев\", \"Мартынов\",\n",
    "     \"Свирский\", \"Икар\", \"Некит\", \"Крымов\", \"Чайковский\", \"Тихомирова\", \"Абель\", \"Гейнц\", \"Агнес\", \"Дитрих\", \"Морган\",\n",
    "     \"Герберт\", \"Хаим\", \"Марти\", \"Майер\", \"Франсуа\", \"Тэйт\", \"Генка\", \"Арнольд\", \"Миронов\", \"Миха\", \"Миша\", \"Мишаня\",\n",
    "     \"Лешек\", \"Олежка\", \"Иванов\", \"Степанов\", \"Сашенек\", \"Фредерик\", \"Реми\", \"Эдик\", \"Серж\", \"Кузнецов\", \"Иванушка\",\n",
    "    \"Самойлов\", \"Мухин\", \"Ибрахим\", \"Брайса\", \"Хеллинга\", \"Каин\", \"Авель\", \"Саня\", \"Кротов\", \"Щербаков\", \"Рогов\", \"Лазарев\",\n",
    "     \"Васенька\", \"Эрклион\", \"Курт\", \"Гарин\", \"Иов\", \"Сьюзи\", \"Сани\", \"Пронин\", \"Николос\", \"Хомич\", \"Френсис\", \"Сизов\",\n",
    "     \"Клюев\", \"Поликарпыч\", \"Поликарпыча\", \"Мышкин\", \"Захарий\", \"Иванцаревич\", \"Плетнёв\", \"Васильев\", \"Джерри\", \"Митяй\",\n",
    "     \"Майкл\", \"Оливер\", \"Рамон\", \"Фреда\", \"Фрэда\", \"Мохинь\", \"Мелис\", \"Амур\", \"Ритик\", \"Альдо\", \"Ярош\", \"Гарик\", \"Гай\",\n",
    "     \"Богданов\", \"Лебедев\", \"Зураб\", \"Самуэль\", \"Иона\", \"Лукас\", \"Сеня\", \"Элвис\", \"Берг\" \"Рональд\", \"Пион\", \"Джони\",\n",
    "     \"Вилли\", \"Керн\", \"Августин\", \"Томпсон\", \"Гришин\", \"Ральф\", \"Робби\", \"Брут\", \"Михайло\", \"Павлов\", \"Костик\",\n",
    "     \"Вельмить\", \"Девид\",\"Дэвид\", \"Сидор\", \"Николаев\", \"Алевтин\", \"Кирюха\", \"Шейла\", \"Налим\", \"Герш\", \"Мишин\", \"Жуков\",\n",
    "     \"Мэй\", \"Лямин\", \"Дир\", \"Микола\", \"Султанбек\", \"Нолана\", \"Первушин\", \"Канис\", \"Майлз\", \"Вова\", \"Гаврил\", \"Себастьян\",\n",
    "     \"Бертрам\", \"Уилла\",\"Рауль\", \"Энж\", \"Голди\", \"Армандо\", \"Дронов\", \"Юрген\", \"Санчёс\", \"Санчес\", \"Смолев\", \"Кристофер\",\n",
    "     \"Ник\", \"Мишка\", \"Алёша\", \"Данька\", \"Валька\", \"Сёма\", \"Говард\", \"Салим\", \"Дэнни\", \"Джозеф\", \"Джефф\", \"Клауд\", \"Хорн\",\n",
    "     \"Кох\", \"Тед\", \"Тор\", \"Муса\", \"Фрэнк\", \"Гордон\", \"Берт\", \"Маркий\", \"Энцо\", \"Мак\", \"Кравцов\",\"Майло\", \"Надир\",\n",
    "     \"Октавий\",  \"Горацио\",  \"Анатолий\", \"Боб\", \"Шон\", \"Энди\", \"Берси\", \"Тун\", \"Герд\", \"Франклин\", \"Яго\", \"Монтана\",\n",
    "     \"Исса\", \"Бажэн\", \"Бажен\", \"Линкольн\", \"Хендриксон\", \"Сэн\", \"Дэнель\", \"Дэниэль\",\"Даниэль\", \"Даниель\", \"Боря\",\n",
    "     \"Лео\", \"Клим\", \"Волков\",\"Павлик\", \"Антоний\", \"Данило\", \"Клаус\", \"Хенсель\", \"Коробкин\", \"Арман\", \"Андреев\" \"Путилин\",\n",
    "    \"Луи\", \"Андре\", \"Ларин\", \"Роджер\", \"Юра\", \"Юр\", \"Грегори\", \"Чен\", \"Костя\", \"Остапенко\", \"Ушаков\", \"Рейнер\", \"Рейнор\",\n",
    "     \"Горбунов\", \"Сайф\", \"Марсик\", \"Улисс\", \"Фредди\", \"Дункан\", \"Франциск\", \"Петька\", \"Алессандро\", \"Клавдий\", \"Саныч\",\n",
    "     \"Стас\", \"Дэн\", \"Стасик\", \"Дэнчик\",\n",
    "     ]\n",
    ")\n",
    "\n",
    "\n",
    "# Список слов, которые заменяются на женские имена\n",
    "GIRLS_NAME_LIST = frozenset(\n",
    "    [\n",
    "        \"Катя\", \"Юля\", \"Кат\", \"Юли\",\"Юлия\", \"Катюша\", \"Ассоль\", \"Джена\", \"Милла\", \"Ульянка\", \"Кадмона\", \"Кэрролл\",\n",
    "        \"Кэрролл\", \"Маша\", \"Аля\", \"Ида\", \"Соня\",\n",
    "        \"Энн\", \"Лайза\", \"Луиза\", \"Луиз\", \"Матильда\", \"Эллис\", \"Машенька\", \"Уиль\", \"Мара\", \"Саманта\", \"Люда\", \"Мэг\",\n",
    "        \"Джейн\",\"Ариан\", \"Валачча\", \"Харальда\", \"Вианда\", \"Джу\", \"Джессика\", \"Людочка\", \"Джесс\", \"Настенёк\",\n",
    "        \"Алин\", \"Алине\", \"Томка\", \"Риша\", \"Силиса\", \"Валюшка\", \"Джуна\", \"Дженна\", \"Элли\", \"Элен\", \"Софа\",\n",
    "        \"Майра\", \"Ксеня\", \"Альбена\", \"Анюта\", \"Пенни\", \"Дастина\", \"Лукреция\", \"Сьюзен\", \"Варёк\", \"Лэй\", \"Эйден\",\n",
    "        \"Маринка\", \"Мария\", \"Ариэль\", \"Рэн\", \"Настасья\", \"Аврора\", \"Алатэя\", \"Дарси\", \"Коркина\", \"Эристина\",\n",
    "        \"Марьин\", \"Лита\", \"Саломея\", \"Камелия\", \"Габриэла\", \"Варя\", \"Душкина\", \"Любаша\", \"Любка\",\"Наташка\", \"Наташа\",\n",
    "        \"Маня\", \"Зина\",\"Верочка\", \"Зинка\", \"Ксюхий\", \"Эли\", \"Кларисса\", \"Николина\", \"Альба\", \"Эрис\", \"Костылёва\",\n",
    "        \"Лизавета\", \"Феня\", \"Зосима\", \"Айсу\", \"Альма\", \"Валери\", \"Энни\", \"Шэль\", \"Аида\", \"Изабель\", \"Катрина\", \"Альбин\",\n",
    "        \"Альбина\", \"Эрина\", \"Сонька\", \"Мелинда\", \"Нюра\", \"Долли\", \"Сюзанна\", \"Мелинда\", \"Лилька\", \"Ося\",\n",
    "        \"Марго\", \"Регин\", \"Регина\", \"Элиса\", \"Джульетта\", \"Триша\", \"Жозефина\", \"Лера\", \"Лерочка\", \"Кейт\",\n",
    "        \"Люся\",  \"Ефросинья\", \"Олафа\",  \"Джилла\", \"Лилечка\", \"Марибель\", \"Ребекка\", \"Лола\", \"Нина\", \"Кэт\", \"Кэти\",\n",
    "        \"Таня\", \"Женя\",\"Танька\", \"Женька\", \"Юля\", \"Юлька\", \"Танечка\", 'Танюша', \"Танин\", \"Жасмина\", \"Кларисса\", \"Женька\",\n",
    "        \"Вивиана\",\"Айсонака\",\"Рита\", \"Мелисса\", \"Эмма\", \"Алавира\", \"Нюся\", \"Шарлотта\", \"Жюстина\", \"Дебби\", \"Клэр\", \"Джэс\",\n",
    "        \"Клодия\", \"Лив\", \"Алёхина\", \"Марьям\", \"Лескюр\",  \"Лайон\", \"Поленька\", \"Эмма\", \"Элвира\", \"Стефани\", \"Ксюша\"\n",
    "        \"Хелма\", \"Ирена\", \"Алёнка\", \"Маша\", \"Машка\", \"Настя\", \"Айседора\", \"Лена\", \"Ленка\", \"Елена\",\"Леночка\", \"Аня\", \"Ксана\",\n",
    "        'Аделия', 'Августа','Августина', 'Авигея', 'Аврора', 'Агата', 'Агнесса', 'Агния', 'Ада', \"Катерина\", \"Галя\"\n",
    "        'Аделина', 'Адель', 'Адельфина', 'Аза', 'Азалия', 'Азиза', 'Аида', 'Айлин', 'Аксинья', \"Марин\", \"Анжела\",\"Анжел\",\n",
    "        'Алевтина', 'Александра', 'Александрина', 'Алика', 'Алина', 'Алира', 'Алира', 'Алиса', \"Натали\"\n",
    "        'Алия', 'Алла', 'Альберта', 'Альбина', 'Альвина', 'Альжбета', 'Алёна', 'Амелия','Амалия', \"Эми\", \"Эмми\",\n",
    "        'Амина', 'Амира', 'Анастасия', 'Ангелина', 'Андриана', 'Анжела', 'Анжелика', 'Лика', \"Аделаида\",\n",
    "        'Анжиолетта', 'Анисья', 'Анита', 'Анна', 'Антонина', 'Анфиса', 'Анэля', 'Ариадна', \"Мариночка\", \"Фиса\"\n",
    "        'Арина', 'Артемида', 'Архелия', 'Арьяна', 'Асида', 'Астра', 'Ася', 'Аурелия', 'Аэлита', \"Шура\", \"Мена\", \"Даша\",\n",
    "        'Аюна', 'Беатриса', 'Белла', 'Береслава', 'Берта', 'Биргит', 'Богдана', 'Божена', 'Борислава',\n",
    "        'Бронислава', 'Валентина', 'Валерия', 'Ванда', 'Ванесса', 'Варвара', 'Василиса', 'Венера',\n",
    "        'Вера', 'Верона', 'Вероника', 'Версавия', 'Веселина', 'Весняна', 'Веста', 'Вида','Видана',\n",
    "        'Виктория', 'Вилора', 'Винетта', 'Виоланта', 'Виолетта', 'Виргиния', 'Виталина', 'Влада',\n",
    "        'Владислава', 'Владлена', 'Властилина', 'Габи', 'Габриэлла', 'Галина', 'Гаянэ', 'Гелана',\n",
    "        'Гелена', 'Гелианна', 'Гелла', 'Генриетта', 'Георгина', 'Гера', 'Герда', 'Гертруда',\n",
    "        'Глафира', 'Глория', 'Гражина', 'Грета', 'Дана', 'Даниэла', 'Дания', 'Данна', 'Данута',\n",
    "        'Дарина', 'Дария', 'Дарья', 'Даша', 'Дарьяна', 'Дебора', 'Джема', 'Джулия', 'Джульетта',\n",
    "        'Диана', 'Дина', 'Динара', 'Диодора', 'Дионисия', 'Диша', 'Доля', 'Доминика','Ника',\n",
    "        'Дэнна', 'Ева', 'Евгения', 'Евдокия', 'Екатерина', 'Елена', 'Елизавета', 'Есения', 'Жаклин',\n",
    "        'Жанна', 'Жасмин', 'Женевьева', 'Жюли', 'Залина', 'Зара', 'Зарина', 'Земфира', 'Зинаида',\n",
    "        'Злата', 'Златослава', 'Зоряна', 'Зоя', 'Иветта','Ветта', 'Ивона', 'Изабелла', 'Изольда',\n",
    "        'Илена', 'Илзе', 'Илона', 'Инара', 'Инга', 'Индира', 'Инесса', 'Инна', 'Иоанна', 'Иоланта',\n",
    "        'Ираида', 'Ирина', 'Ирма', 'Ирэн', 'Ирэна', 'Калерия', 'Камилла', 'Капитолина', 'Кара',\n",
    "        'Карина', 'Кармелитта', 'Мелитта', 'Каролина', 'Каторина', 'Келен', 'Кира', 'Клавдия',\n",
    "        'Клара', 'Крис', 'Кристина', 'Ксения', 'Лада', 'Лайма', 'Лали', 'Лана', 'Ландыш', 'Лариса',\n",
    "        'Лаура', 'Лейла', 'Леся', 'Лея', 'Лиана', 'Лигия', 'Лидия', 'Лиза', 'Лика', 'Лили', 'Лилия',\n",
    "        'Лилу', 'Лина', 'Лира', 'Лия', 'Луиза', 'Лунара', 'Любава', 'Любовь', 'Людмила', 'Ляля', 'Магда',\n",
    "        'Магдалина', 'Майя', 'Малика', 'Мальта', 'Маргарита', 'Марианна', 'Марина', 'Мариша', 'Мария',\n",
    "        'Марта', 'Мартина', 'Марфа', 'Марьяна', 'Мелиана', 'Мелитта', 'Мериса', 'Мила', 'Милана', 'Милда',\n",
    "        'Милена', 'Милиса', 'Милолика', 'Милослава', 'Мирра', 'Мишель', 'Мия', 'Моника', 'Моник',\n",
    "        'Муза', 'Мэри', 'Надежда', 'Надя', 'Нания', 'Наоми', 'Наталия', 'Наталья', 'Нева', 'Нега', 'Нелли',\n",
    "        'Неолина', 'Ника', 'Никки', 'Николь', 'Нила', 'Неонила', 'Нина', 'Нинна', 'Номи', 'Нонна', 'Нора',\n",
    "        'Оксана', 'Октябрина', 'Олеся', 'Алеся', 'Ольга', 'Патрисия', 'Пелагея', 'Полианна', 'Полина',\n",
    "            'Прасковья', 'Радмила', 'Радослава', 'Раиса', 'Ралина', 'Рамина', 'Рамина', 'Рая', 'Регина',\n",
    "            'Риана', 'Римма', 'Роза', 'Розалия', 'Розалина', 'Роксалана', 'Роксана', 'Романа', 'Руслана',\n",
    "        'Сабина', 'Сабрина', 'Санда', 'Сандра', 'Александра', 'Санта', 'Сара', 'Сафина', 'Светлана',\n",
    "        'Святослава', 'Северина', 'Селена', 'Серафима', 'Силика', 'Сильва', 'Сильвия', 'Сима', 'Симона',\n",
    "        'Снежана', 'София', 'Софья', 'Станислава', 'Стелла', 'Стефания', 'Сусанна', 'Таира', 'Таисия',\n",
    "        'Тала', 'Тамара', 'Татьяна', 'Тереза', 'Томила', 'Триана', 'Ульна', 'Ульяна', 'Уля', 'Устинья',\n",
    "        'Фаиза', 'Фаина', 'Фаня', 'Фанни', 'Фая', 'Фелиция', 'Феодосия', 'Фия', 'Флора', 'Франсуаза', 'Фрида',\n",
    "        'Хана', 'Харита', 'Харитина', 'Хельга', 'Хильда', 'Христина', 'Цветана', 'Чеслава', 'Эвелина', 'Эдда',\n",
    "        'Эдилия', 'Эдита', 'Эдуарда', 'Эжени', 'Элеонора', 'Элиза', 'Элизабет', 'Элина', 'Эллина',\n",
    "        'Элла', 'Эллада', 'Элоиза', 'Эльвина', 'Эльвира', 'Эльга', 'Эльза', 'Эльмира', 'Эля',\n",
    "        'Эмбер', 'Эмилия', 'Эмма', 'Эрида', 'Эрика', 'Эстелла', 'Эшли', 'Юзефа', 'Юланта',\n",
    "        'Юлиана', 'Юлия', 'Юна', 'Юнона', 'Юстина', 'Юфеза', 'Ядвига', 'Яна', 'Янина', 'Янита', 'Ярослава', 'Ясмина',\n",
    "        'Саша','Ксюша', 'Аннет','Гермиона','Фелла','Вика', \"Нея\", \"Рина\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Список слов, которые не влияют на смысл непосредственно, и не обрабатываются предыдущими фильтрами.\n",
    "STOP_WORD_LIST = frozenset([\n",
    "    'уже', 'самый', 'мочь', 'говорить', 'являться', 'быть', 'хотеть', 'стать', 'знать', 'начать',\n",
    "    'сказать', 'брать', 'является', 'есть', 'иметь', 'хотеть', 'содержаться', 'существует', 'сделать','делать','оказаться'\n",
    "    'очень', 'минимально', 'максимально', 'абсолютно', 'огромный', 'предельно', 'сильно', 'слабо', 'много', 'мало','немного','немало'\n",
    "    'несколько', 'сразу', 'потом', 'ещё', 'пока', 'куда', 'туда',\n",
    "    'наиболее', 'наименьшее', 'самый',\n",
    "    'тут','оба', 'ктото', 'както','чтото', 'ктонибудь', 'чтонибудь', 'какойто', 'такойто',\n",
    "    'где','раз','там','дать','теперь','сейчас','здесь', 'тоже', 'там', 'сям',\n",
    "    'прийти', 'скоро', 'долго', 'выходить','слушать','вообще','случиться',\n",
    "    'поэтому','потому', 'почему', 'почти', \"едва\", 'чуть',\n",
    "    'снова', 'опять', 'вновь', 'всегда','никогда','некогда','вдруг','внезапно',\n",
    "    'хорошо', \"нехорошо\", \"плохо\", \"неплохо\", \"нормально\",\n",
    "    'всего', 'вцелом', \"целиком\", \"полностью\", \"вместе\", \"несколько\",\n",
    "    'совершенно', 'довольно', \"более\", \"менее\"\n",
    "])\n",
    "\n",
    "\n",
    "def isfloat(value):\n",
    "    '''\n",
    "    Проверяем можно ли привести токен к числу с плавающей точкой\n",
    "    '''\n",
    "    try:\n",
    "        return float(value)\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "@functools.lru_cache(maxsize=100)\n",
    "def map_numbers(word):\n",
    "    '''\n",
    "    Заменяем числа диапазонами, в которых они находятся.\n",
    "\n",
    "    '''\n",
    "    value = isfloat(word)\n",
    "    if value == False:\n",
    "        if value == 'ноль':\n",
    "            return '0'\n",
    "        elif value in ['раз', \"один\"]:\n",
    "            return '1'\n",
    "        elif value == \"два\":\n",
    "            return '2'\n",
    "        elif value == \"три\":\n",
    "            return '3'\n",
    "        elif value in [\"четыре\", \"пять\", \"шесть\", \"семь\", \"восемь\", \"девять\", \"десять\"]:\n",
    "            return '__число_между_3_и_10__'\n",
    "        elif value in ['одиннадцать', \"двенадцать\", \"тринадцать\", \"четырнадцать\", \"пятнадцать\",\n",
    "                       \"шеснадцать\", \"семнадцать\", \"восемнадцать\", \"девятнадцать\", \"двадцать\"]:\n",
    "            return '__число_между_10_и_20__'\n",
    "        elif value in ['тридцать', \"сорок\", \"пятьдесят\"]:\n",
    "            return '__число_между_20_и_50__'\n",
    "        elif value in [\"шестьдесят\", \"семьдесят\", \"восемьдесят\", \"девяносто\", \"сто\"]:\n",
    "            return '__число_между_50_и_100__'\n",
    "        elif value in [\"двести\", \"триста\", \"четыреста\", \"пятьсот\"]:\n",
    "            return '__число_между_100_и_500__'\n",
    "        elif value in [\"шестьсот\", \"семьсот\", \"восемьсот\", \"девятьсот\", \"тысяча\", \"тыща\", \"тысеча\"]:\n",
    "            return '__число_между_500_и_1000__'\n",
    "        else:\n",
    "            return\n",
    "    if value < 0:\n",
    "        return '__negative_number__'\n",
    "    elif value == 0:\n",
    "        return '0'\n",
    "    elif 0 < value < 1:\n",
    "        return '__number_in_0_1__'\n",
    "    elif 1 <= value <= 3:\n",
    "        str(value)\n",
    "    elif 3 < value <= 10:\n",
    "        return '__число_между_3_и_10__'\n",
    "    elif 10 < value <= 20:\n",
    "        return '__число_между_10_и_20__'\n",
    "    elif 20 < value <= 50:\n",
    "        return '__число_между_20_и_50__'\n",
    "    elif 50 < value <= 100:\n",
    "        return '__число_между_50_и_100__'\n",
    "    elif 100 < value <= 500:\n",
    "        return '__число_между_100_и_500__'\n",
    "    elif 500 < value <= 1000:\n",
    "        return '__число_между_500_и_1000__'\n",
    "    elif 1000 < value <= 1500:\n",
    "        return '__число_между_1000_и_1500__'\n",
    "    elif 1500 < value <= 1600:\n",
    "        return '__число_между_1500_и_1600__'\n",
    "    elif 1600 < value <= 1700:\n",
    "        return '__число_между_1600_и_1700__'\n",
    "    elif 1700 < value <= 1800:\n",
    "        return '__число_между_1700_и_1800__'\n",
    "    elif 1800 < value <= 1900:\n",
    "        return '__число_между_1800_и_1900__'\n",
    "    elif 1900 < value <= 2100:\n",
    "        return str(value)\n",
    "    elif 2100 < value <= 5000:\n",
    "        return '__число_между_2100_и_5000__'\n",
    "    elif 5000 < value <= 10000:\n",
    "        return '__число_между_5000_и_10000__'\n",
    "    elif 10000 < value:\n",
    "        return '__число_больше_10000__'\n",
    "\n",
    "@functools.lru_cache(maxsize=1000)\n",
    "def not_cyrilic(word):\n",
    "    if re.match('.+[A-Za-z]+.+', word):\n",
    "        return None\n",
    "    return word\n",
    "\n",
    "\n",
    "@functools.lru_cache(maxsize=1000000)\n",
    "def parse_token(normal_form):\n",
    "    \n",
    "    word = normal_form\n",
    "    if not word: # Пустая строка\n",
    "        return ''\n",
    "\n",
    "    if word.isupper() and len(word)==2:\n",
    "        return word\n",
    "\n",
    "\n",
    "    if word in [\n",
    "        #'I', английское z\n",
    "        # 'XL', размер\n",
    "        # 'XXX', категория контента\n",
    "        # 'C', язык программирования\n",
    "        # 'CD', носитель данных\n",
    "        # 'DC', издатель комиксов\n",
    "\n",
    "        'II','III', 'IIII'\n",
    "        'IV', 'V', 'VI', 'VII', 'VIII',\n",
    "        'IX', 'X', 'XX',\n",
    "        'L', 'LX', 'LXX', 'LXXX',\n",
    "        'XC', 'CC', 'CCC',\n",
    "        'D',  'DCC', 'DCCC',\n",
    "        'CM', 'M', 'MM', 'MMM',\n",
    "        'MMMCMXCIX'\n",
    "    ]:\n",
    "        return '__РИМСКОЕ_ЧИСЛО_%s__' % word\n",
    "\n",
    "    if not not_cyrilic(word):\n",
    "        return '__слово_на_латинице__'\n",
    "\n",
    "    # if p.tag.grammemes & STOP_POS:\n",
    "    #     return None\n",
    "\n",
    "    if (word in STOP_WORD_LIST):\n",
    "        return ''\n",
    "\n",
    "    if all((i == word[0] for i in word)):\n",
    "        return ''\n",
    "    \n",
    "    word_is_boy = (\n",
    "        (word.capitalize() in BOYS_NAME_LIST) or\n",
    "        (word.lower().capitalize() in BOYS_NAME_LIST)\n",
    "    )\n",
    "    word_is_girl = (\n",
    "         (word.capitalize() in GIRLS_NAME_LIST) or\n",
    "         (word.lower().capitalize() in GIRLS_NAME_LIST)\n",
    "    )\n",
    "\n",
    "    if word_is_boy:\n",
    "        return '__МУЖСКОЕ_ИМЯ__'\n",
    "    elif word_is_girl:\n",
    "        return '__ЖЕНСКОЕ_ИМЯ__'\n",
    "\n",
    "    is_number = map_numbers(word)\n",
    "    if is_number:\n",
    "        return is_number\n",
    "\n",
    "    if len(word.strip()) <3:\n",
    "        return ''\n",
    "\n",
    "    return word\n",
    "\n",
    "\n",
    "@functools.lru_cache()\n",
    "def normalize_by_mystem(from_my_stem):\n",
    "    from_my_stem = json.loads(from_my_stem)\n",
    "    if not from_my_stem['text'].strip():\n",
    "        return ''\n",
    "    \n",
    "    if 'analysis' in from_my_stem and from_my_stem['analysis']:\n",
    "        try:\n",
    "            return parse_token(from_my_stem.get('analysis', [{}])[0].get('lex'))\n",
    "        except:\n",
    "            print(from_my_stem)\n",
    "            raise Exception\n",
    "    else:\n",
    "        return parse_token(from_my_stem.get('text'))\n",
    "\n",
    "def test(from_my_stem):\n",
    "    return from_my_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache(maxsize=1000000)\n",
    "def preprocessing(string):\n",
    "    return ' '.join(\n",
    "        map(\n",
    "            normalize_by_mystem,\n",
    "#             normalize_by_mystem,\n",
    "            [\n",
    "                json.dumps(j)\n",
    "                for j in mystem.analyze(\n",
    "                    ' '.join(\n",
    "                        (\n",
    "                            i\n",
    "                            for i in map(clear_string, string.split())\n",
    "                            if len(i) > 2\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    return\n",
    "\n",
    "def iter_sentence():\n",
    "    with open('./big_train.csv','r') as f:\n",
    "        f.readline()\n",
    "        for line in f:\n",
    "            yield preprocessing(line.strip().split(',')[3].lower()).split()\n",
    "            \n",
    "    with open('./rating_test_without_rating.csv', 'r') as f:\n",
    "        f.readline()\n",
    "        for line in f:\n",
    "            yield preprocessing(line.strip().split(',')[2].lower()).split()\n",
    "            \n",
    "class SentenseIterator():\n",
    "    def __iter__(self):\n",
    "        yield from iter_sentence()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_iter_sentence():\n",
    "    with open('./big_train.csv','r') as f:\n",
    "        f.readline()\n",
    "        for line in f:\n",
    "            yield preprocessing(line.strip().split(',')[3].lower()).split()\n",
    "            \n",
    "class TrainSentenseIterator():\n",
    "    def __iter__(self):\n",
    "        yield from train_iter_sentence()\n",
    "        \n",
    "\n",
    "def test_iter_sentence():\n",
    "    with open('./rating_test_without_rating.csv', 'r') as f:\n",
    "        f.readline()\n",
    "        for line in f:\n",
    "            yield preprocessing(line.strip().split(',')[2].lower()).split()\n",
    "            \n",
    "class TestSentenseIterator():\n",
    "    def __iter__(self):\n",
    "        yield from test_iter_sentence()\n",
    "        \n",
    "train_sentences = TrainSentenseIterator()\n",
    "test_sentences = TestSentenseIterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = SentenseIterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "    max_vocab_size=10**5*2,\n",
    "    min_count=5,\n",
    "    workers=multiprocessing.cpu_count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-22 17:42:56,404 : INFO : collecting all words and their counts\n",
      "2018-02-22 17:42:58,778 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-02-22 17:44:03,840 : INFO : PROGRESS: at sentence #10000, processed 430261 words, keeping 32691 word types\n",
      "2018-02-22 17:45:04,830 : INFO : PROGRESS: at sentence #20000, processed 854636 words, keeping 48247 word types\n",
      "2018-02-22 17:46:07,215 : INFO : PROGRESS: at sentence #30000, processed 1286765 words, keeping 60734 word types\n",
      "2018-02-22 17:47:07,250 : INFO : PROGRESS: at sentence #40000, processed 1724216 words, keeping 72253 word types\n",
      "2018-02-22 17:48:12,110 : INFO : PROGRESS: at sentence #50000, processed 2151102 words, keeping 82793 word types\n",
      "2018-02-22 17:49:11,284 : INFO : PROGRESS: at sentence #60000, processed 2564945 words, keeping 92323 word types\n",
      "2018-02-22 17:50:14,661 : INFO : PROGRESS: at sentence #70000, processed 2992124 words, keeping 101523 word types\n",
      "2018-02-22 17:51:11,830 : INFO : PROGRESS: at sentence #80000, processed 3407468 words, keeping 110196 word types\n",
      "2018-02-22 17:52:04,767 : INFO : PROGRESS: at sentence #90000, processed 3834211 words, keeping 118468 word types\n",
      "2018-02-22 17:52:55,854 : INFO : PROGRESS: at sentence #100000, processed 4259914 words, keeping 126660 word types\n",
      "2018-02-22 17:53:47,176 : INFO : PROGRESS: at sentence #110000, processed 4691623 words, keeping 134320 word types\n",
      "2018-02-22 17:54:37,979 : INFO : PROGRESS: at sentence #120000, processed 5126777 words, keeping 141800 word types\n",
      "2018-02-22 17:55:26,673 : INFO : PROGRESS: at sentence #130000, processed 5542970 words, keeping 148639 word types\n",
      "2018-02-22 17:56:15,634 : INFO : PROGRESS: at sentence #140000, processed 5960133 words, keeping 155699 word types\n",
      "2018-02-22 17:57:04,758 : INFO : PROGRESS: at sentence #150000, processed 6383137 words, keeping 162519 word types\n",
      "2018-02-22 17:58:01,907 : INFO : PROGRESS: at sentence #160000, processed 6894947 words, keeping 170382 word types\n",
      "2018-02-22 17:59:07,669 : INFO : PROGRESS: at sentence #170000, processed 7489928 words, keeping 178471 word types\n",
      "2018-02-22 18:00:26,402 : INFO : PROGRESS: at sentence #180000, processed 8077610 words, keeping 186572 word types\n",
      "2018-02-22 18:01:38,910 : INFO : PROGRESS: at sentence #190000, processed 8671878 words, keeping 194451 word types\n",
      "2018-02-22 18:02:28,055 : INFO : pruned out 0 tokens with count <=1 (before 200002, after 200002)\n",
      "2018-02-22 18:02:28,261 : INFO : pruned out 122530 tokens with count <=2 (before 200005, after 77475)\n",
      "2018-02-22 18:02:50,410 : INFO : PROGRESS: at sentence #200000, processed 9258312 words, keeping 80722 word types\n",
      "2018-02-22 18:04:08,184 : INFO : PROGRESS: at sentence #210000, processed 9846193 words, keeping 90696 word types\n",
      "2018-02-22 18:05:08,885 : INFO : PROGRESS: at sentence #220000, processed 10421055 words, keeping 100243 word types\n",
      "2018-02-22 18:06:17,155 : INFO : PROGRESS: at sentence #230000, processed 11004503 words, keeping 109972 word types\n",
      "2018-02-22 18:07:08,761 : INFO : collected 116876 word types from a corpus of 11444301 raw words and 237591 sentences\n",
      "2018-02-22 18:07:08,763 : INFO : Loading a fresh vocabulary\n",
      "2018-02-22 18:07:09,251 : INFO : min_count=5 retains 41046 unique words (35% of original 116876, drops 75830)\n",
      "2018-02-22 18:07:09,253 : INFO : min_count=5 leaves 11185179 word corpus (98% of original 11321771, drops 136592)\n",
      "2018-02-22 18:07:09,525 : INFO : deleting the raw counts dictionary of 116876 items\n",
      "2018-02-22 18:07:09,541 : INFO : sample=0.001 downsamples 42 most-common words\n",
      "2018-02-22 18:07:09,542 : INFO : downsampling leaves estimated 10136254 word corpus (90.6% of prior 11185179)\n",
      "2018-02-22 18:07:09,544 : INFO : estimated required memory for 41046 words and 100 dimensions: 53359800 bytes\n",
      "2018-02-22 18:07:09,822 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "model.build_vocab(sentences=sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-15 22:05:08,420 : INFO : training model with 4 workers on 41046 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-02-15 22:05:09,459 : INFO : PROGRESS: at 0.91% examples, 248391 words/s, in_qsize 0, out_qsize 1\n",
      "2018-02-15 22:05:10,494 : INFO : PROGRESS: at 2.09% examples, 272751 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:11,525 : INFO : PROGRESS: at 3.74% examples, 326654 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:12,534 : INFO : PROGRESS: at 5.34% examples, 353400 words/s, in_qsize 0, out_qsize 1\n",
      "2018-02-15 22:05:13,538 : INFO : PROGRESS: at 6.84% examples, 362795 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:14,566 : INFO : PROGRESS: at 8.45% examples, 370657 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:15,615 : INFO : PROGRESS: at 9.97% examples, 372695 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:16,625 : INFO : PROGRESS: at 11.49% examples, 375962 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:17,680 : INFO : PROGRESS: at 13.06% examples, 378595 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:18,691 : INFO : PROGRESS: at 14.48% examples, 378097 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:19,702 : INFO : PROGRESS: at 16.03% examples, 381412 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:20,719 : INFO : PROGRESS: at 17.63% examples, 384933 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:21,725 : INFO : PROGRESS: at 19.27% examples, 388198 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:22,735 : INFO : PROGRESS: at 20.83% examples, 390245 words/s, in_qsize 1, out_qsize 0\n",
      "2018-02-15 22:05:23,738 : INFO : PROGRESS: at 22.24% examples, 392871 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:24,740 : INFO : PROGRESS: at 23.11% examples, 388794 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-15 22:05:25,749 : INFO : PROGRESS: at 24.32% examples, 392222 words/s, in_qsize 0, out_qsize 1\n",
      "2018-02-15 22:05:26,776 : INFO : PROGRESS: at 25.55% examples, 395341 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:27,790 : INFO : PROGRESS: at 26.74% examples, 397946 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:28,803 : INFO : PROGRESS: at 28.03% examples, 401639 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:29,830 : INFO : PROGRESS: at 29.27% examples, 403892 words/s, in_qsize 0, out_qsize 1\n",
      "2018-02-15 22:05:30,836 : INFO : PROGRESS: at 30.55% examples, 406666 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:31,844 : INFO : PROGRESS: at 31.80% examples, 408741 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:32,859 : INFO : PROGRESS: at 33.02% examples, 410222 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:33,861 : INFO : PROGRESS: at 34.45% examples, 410683 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:34,878 : INFO : PROGRESS: at 36.14% examples, 411775 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:35,911 : INFO : PROGRESS: at 37.72% examples, 411974 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:36,937 : INFO : PROGRESS: at 39.25% examples, 411943 words/s, in_qsize 1, out_qsize 0\n",
      "2018-02-15 22:05:37,942 : INFO : PROGRESS: at 40.91% examples, 412780 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:38,952 : INFO : PROGRESS: at 42.58% examples, 413475 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:39,961 : INFO : PROGRESS: at 44.27% examples, 414438 words/s, in_qsize 1, out_qsize 0\n",
      "2018-02-15 22:05:40,963 : INFO : PROGRESS: at 45.73% examples, 413529 words/s, in_qsize 0, out_qsize 1\n",
      "2018-02-15 22:05:41,968 : INFO : PROGRESS: at 47.32% examples, 413974 words/s, in_qsize 0, out_qsize 1\n",
      "2018-02-15 22:05:42,985 : INFO : PROGRESS: at 49.01% examples, 414955 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:43,998 : INFO : PROGRESS: at 50.69% examples, 415984 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:45,005 : INFO : PROGRESS: at 52.10% examples, 414625 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:46,010 : INFO : PROGRESS: at 53.78% examples, 415471 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:47,011 : INFO : PROGRESS: at 55.30% examples, 415839 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:48,013 : INFO : PROGRESS: at 56.45% examples, 416257 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:49,013 : INFO : PROGRESS: at 57.67% examples, 417341 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:50,016 : INFO : PROGRESS: at 58.84% examples, 417702 words/s, in_qsize 0, out_qsize 1\n",
      "2018-02-15 22:05:51,017 : INFO : PROGRESS: at 59.86% examples, 417041 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:52,042 : INFO : PROGRESS: at 60.90% examples, 415972 words/s, in_qsize 1, out_qsize 0\n",
      "2018-02-15 22:05:53,103 : INFO : PROGRESS: at 61.82% examples, 413824 words/s, in_qsize 2, out_qsize 1\n",
      "2018-02-15 22:05:54,131 : INFO : PROGRESS: at 63.06% examples, 414596 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:55,137 : INFO : PROGRESS: at 64.33% examples, 415696 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:56,144 : INFO : PROGRESS: at 65.55% examples, 416344 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:57,153 : INFO : PROGRESS: at 66.88% examples, 417350 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:58,175 : INFO : PROGRESS: at 68.56% examples, 417774 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:05:59,184 : INFO : PROGRESS: at 70.18% examples, 418103 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:06:00,197 : INFO : PROGRESS: at 71.85% examples, 418767 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:06:01,209 : INFO : PROGRESS: at 73.47% examples, 419044 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:06:02,209 : INFO : PROGRESS: at 75.12% examples, 419246 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:06:03,221 : INFO : PROGRESS: at 76.69% examples, 419190 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:06:04,235 : INFO : PROGRESS: at 78.36% examples, 419426 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:06:05,269 : INFO : PROGRESS: at 79.99% examples, 419519 words/s, in_qsize 0, out_qsize 1\n",
      "2018-02-15 22:06:06,295 : INFO : PROGRESS: at 81.59% examples, 419506 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:06:07,310 : INFO : PROGRESS: at 83.24% examples, 419858 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:06:08,323 : INFO : PROGRESS: at 84.96% examples, 420394 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:06:09,333 : INFO : PROGRESS: at 86.60% examples, 420493 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:06:10,351 : INFO : PROGRESS: at 88.32% examples, 420955 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:06:11,359 : INFO : PROGRESS: at 89.52% examples, 421373 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:06:12,384 : INFO : PROGRESS: at 90.76% examples, 421947 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:06:13,396 : INFO : PROGRESS: at 92.01% examples, 422454 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:06:14,398 : INFO : PROGRESS: at 93.20% examples, 422883 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:06:15,400 : INFO : PROGRESS: at 94.41% examples, 423297 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:06:16,406 : INFO : PROGRESS: at 95.63% examples, 423680 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:06:17,418 : INFO : PROGRESS: at 96.88% examples, 424135 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:06:18,431 : INFO : PROGRESS: at 98.08% examples, 424297 words/s, in_qsize 1, out_qsize 1\n",
      "2018-02-15 22:06:19,451 : INFO : PROGRESS: at 99.24% examples, 424304 words/s, in_qsize 0, out_qsize 0\n",
      "2018-02-15 22:06:20,017 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-02-15 22:06:20,023 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-02-15 22:06:20,032 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-02-15 22:06:20,043 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-02-15 22:06:20,045 : INFO : training on 34332903 raw words (30408518 effective words) took 71.6s, 424635 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30408518"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(sentences, epochs=3,  total_examples=model.corpus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['что',\n",
       " '__слово_на_латинице__',\n",
       " 'очень',\n",
       " 'это',\n",
       " 'как',\n",
       " 'этот',\n",
       " 'книга',\n",
       " 'все',\n",
       " 'для',\n",
       " 'весь',\n",
       " 'так',\n",
       " 'который',\n",
       " 'еще',\n",
       " 'такой',\n",
       " 'один',\n",
       " 'вкусный',\n",
       " 'хороший',\n",
       " 'место',\n",
       " 'свой',\n",
       " 'только',\n",
       " 'если',\n",
       " 'заведение',\n",
       " 'просто',\n",
       " 'можно',\n",
       " 'мой',\n",
       " 'они',\n",
       " 'нет',\n",
       " 'или',\n",
       " 'человек',\n",
       " 'заказывать',\n",
       " '__МУЖСКОЕ_ИМЯ__',\n",
       " 'она',\n",
       " 'блюдо',\n",
       " 'даже',\n",
       " 'время',\n",
       " 'понравиться',\n",
       " 'официант',\n",
       " 'себя',\n",
       " 'вот',\n",
       " 'когда',\n",
       " 'меню',\n",
       " 'большой',\n",
       " 'другой',\n",
       " 'сам',\n",
       " 'цена',\n",
       " 'первый',\n",
       " 'день',\n",
       " 'тот',\n",
       " 'вкусно',\n",
       " 'год',\n",
       " 'еда',\n",
       " 'ребенок',\n",
       " 'при',\n",
       " 'приятный',\n",
       " 'приносить',\n",
       " 'после',\n",
       " 'чтобы',\n",
       " 'заказ',\n",
       " 'кто',\n",
       " 'наш',\n",
       " 'спасибо',\n",
       " '__ЖЕНСКОЕ_ИМЯ__',\n",
       " 'каждый',\n",
       " 'обслуживание',\n",
       " 'ресторан',\n",
       " 'без',\n",
       " 'отличный',\n",
       " 'становиться',\n",
       " 'читать',\n",
       " 'кухня',\n",
       " 'кофе',\n",
       " 'хотеться',\n",
       " 'автор',\n",
       " 'про',\n",
       " 'понимать',\n",
       " 'чем',\n",
       " 'салат',\n",
       " 'вкус',\n",
       " 'интерьер',\n",
       " 'минута',\n",
       " 'интересный',\n",
       " 'приходить',\n",
       " 'друг',\n",
       " 'конечно',\n",
       " 'персонал',\n",
       " 'хотя',\n",
       " 'столик',\n",
       " 'решать',\n",
       " 'быстро',\n",
       " 'ждать',\n",
       " 'работать',\n",
       " 'рекомендовать',\n",
       " 'качество',\n",
       " 'стол',\n",
       " 'общий',\n",
       " 'вечер',\n",
       " 'какой',\n",
       " 'два',\n",
       " '__число_между_100_и_500__',\n",
       " 'данный',\n",
       " 'любить',\n",
       " 'новый',\n",
       " 'кафе',\n",
       " 'оказываться',\n",
       " 'сюда',\n",
       " 'зал',\n",
       " 'его',\n",
       " 'надо',\n",
       " 'ничто',\n",
       " 'чай',\n",
       " 'оставаться',\n",
       " 'именно',\n",
       " 'работа',\n",
       " 'написать',\n",
       " 'отзыв',\n",
       " 'пиво',\n",
       " 'компания',\n",
       " 'пицца',\n",
       " 'думать',\n",
       " 'приходиться',\n",
       " 'ваш',\n",
       " 'начинать',\n",
       " 'ролл',\n",
       " 'давать',\n",
       " 'вид',\n",
       " 'жизнь',\n",
       " 'находить',\n",
       " 'выбор',\n",
       " 'вопрос',\n",
       " 'нравиться',\n",
       " 'через',\n",
       " 'зайти',\n",
       " 'дело',\n",
       " 'второй',\n",
       " 'прочитывать',\n",
       " 'нужно',\n",
       " 'взять',\n",
       " 'девушка',\n",
       " 'бар',\n",
       " 'попробовать',\n",
       " 'соус',\n",
       " 'атмосфера',\n",
       " 'подходить',\n",
       " 'под',\n",
       " 'музыка',\n",
       " 'стоять',\n",
       " 'гость',\n",
       " 'бургер',\n",
       " 'суп',\n",
       " 'мясо',\n",
       " 'совсем',\n",
       " 'десерт',\n",
       " 'приятно',\n",
       " 'маленький',\n",
       " 'порция',\n",
       " 'напиток',\n",
       " 'выбирать',\n",
       " 'плюс',\n",
       " 'слово',\n",
       " 'писать',\n",
       " 'особенно',\n",
       " 'получать',\n",
       " 'ходить',\n",
       " 'минус',\n",
       " 'разный',\n",
       " 'идти',\n",
       " 'часто',\n",
       " 'город',\n",
       " 'впечатление',\n",
       " 'последний',\n",
       " 'рубль',\n",
       " 'сидеть',\n",
       " 'достаточно',\n",
       " 'официантка',\n",
       " 'час',\n",
       " 'проблема',\n",
       " 'коктейль',\n",
       " 'бывать',\n",
       " 'любой',\n",
       " 'уютный',\n",
       " 'действительно',\n",
       " 'купить',\n",
       " 'целое',\n",
       " 'посещать',\n",
       " 'история',\n",
       " 'итог',\n",
       " 'прекрасный',\n",
       " 'сегодня',\n",
       " 'также',\n",
       " 'отмечать',\n",
       " 'правда',\n",
       " 'пара',\n",
       " 'вполне',\n",
       " 'любимый',\n",
       " 'случай',\n",
       " 'уровень',\n",
       " 'красивый',\n",
       " 'видеть',\n",
       " 'никто',\n",
       " 'должный',\n",
       " 'получаться',\n",
       " 'страница',\n",
       " 'советовать',\n",
       " 'стоить',\n",
       " 'деньги',\n",
       " 'предлагать',\n",
       " 'оставлять',\n",
       " 'проходить',\n",
       " 'горячий',\n",
       " 'готовить',\n",
       " 'паста',\n",
       " 'момент',\n",
       " 'рано',\n",
       " 'подруга',\n",
       " 'кстати',\n",
       " 'рука',\n",
       " 'обязательно',\n",
       " 'карта',\n",
       " 'точно',\n",
       " 'единственный',\n",
       " 'счет',\n",
       " 'бизнес',\n",
       " 'небольшой',\n",
       " 'язык',\n",
       " 'довольный',\n",
       " 'встречать',\n",
       " 'вежливый',\n",
       " 'свежий',\n",
       " 'например',\n",
       " 'никакой',\n",
       " 'помогать',\n",
       " 'пойти',\n",
       " 'высокий',\n",
       " 'конец',\n",
       " 'нужный',\n",
       " 'уходить',\n",
       " 'замечательный',\n",
       " 'давно',\n",
       " 'интересно',\n",
       " 'хоть',\n",
       " 'простой',\n",
       " 'внимание',\n",
       " 'некоторый',\n",
       " 'картинка',\n",
       " 'далеко',\n",
       " 'полный',\n",
       " 'проводить',\n",
       " 'взгляд',\n",
       " 'часть',\n",
       " 'удовольствие',\n",
       " 'вход',\n",
       " 'обед',\n",
       " 'сторона',\n",
       " 'клиент',\n",
       " 'порадовать',\n",
       " 'вроде',\n",
       " 'три',\n",
       " 'ребята',\n",
       " 'количество',\n",
       " 'оно',\n",
       " 'радовать',\n",
       " 'отдельный',\n",
       " 'полезный',\n",
       " 'принимать',\n",
       " 'ведь',\n",
       " 'очередь',\n",
       " 'иногда',\n",
       " 'видимо',\n",
       " 'легко',\n",
       " 'муж',\n",
       " 'спрашивать',\n",
       " 'находиться',\n",
       " 'пробовать',\n",
       " 'смотреть',\n",
       " 'обычный',\n",
       " 'попросить',\n",
       " 'добавлять',\n",
       " 'приветливый',\n",
       " 'информация',\n",
       " 'иллюстрация',\n",
       " 'слишком',\n",
       " 'пример',\n",
       " 'народ',\n",
       " 'считать',\n",
       " 'обслуживать',\n",
       " 'забывать',\n",
       " 'увидеть',\n",
       " 'книжка',\n",
       " 'заходить',\n",
       " 'подавать',\n",
       " 'название',\n",
       " 'рассказывать',\n",
       " 'тема',\n",
       " 'глаз',\n",
       " 'курица',\n",
       " 'смочь',\n",
       " 'уютно',\n",
       " 'кальян',\n",
       " 'изза',\n",
       " 'вернуться',\n",
       " 'милый',\n",
       " 'основной',\n",
       " 'отношение',\n",
       " 'обстановка',\n",
       " 'текст',\n",
       " 'подача',\n",
       " 'вода',\n",
       " 'средний',\n",
       " 'плохой',\n",
       " 'издание',\n",
       " 'посетитель',\n",
       " 'удобный',\n",
       " 'сыр',\n",
       " 'казаться',\n",
       " 'либо',\n",
       " 'посещение',\n",
       " 'удивлять',\n",
       " 'тарелка',\n",
       " 'ощущение',\n",
       " 'бумага',\n",
       " 'многий',\n",
       " 'доставка',\n",
       " 'неплохой',\n",
       " 'вариант',\n",
       " 'восторг',\n",
       " 'открывать',\n",
       " 'тогда',\n",
       " 'обычно',\n",
       " 'появляться',\n",
       " 'перед',\n",
       " 'готовый',\n",
       " 'главное',\n",
       " 'возможно',\n",
       " 'отвечать',\n",
       " 'узнавать',\n",
       " 'сервис',\n",
       " 'рядом',\n",
       " 'отлично',\n",
       " 'использовать',\n",
       " 'больше',\n",
       " 'подарок',\n",
       " 'пить',\n",
       " 'сожаление',\n",
       " 'замечать',\n",
       " 'молодой',\n",
       " 'возможность',\n",
       " 'детский',\n",
       " 'центр',\n",
       " 'нормальный',\n",
       " 'серия',\n",
       " 'попадать',\n",
       " 'душа',\n",
       " 'приготавливать',\n",
       " 'рождение',\n",
       " 'ситуация',\n",
       " 'желание',\n",
       " 'ответ',\n",
       " 'любитель',\n",
       " 'ожидание',\n",
       " 'повар',\n",
       " 'пора',\n",
       " 'посидеть',\n",
       " 'сеть',\n",
       " 'сайт',\n",
       " 'описывать',\n",
       " 'вино',\n",
       " 'вчера',\n",
       " 'жить',\n",
       " 'бизнесланч',\n",
       " 'посмотреть',\n",
       " 'добрый',\n",
       " 'кроме',\n",
       " 'фото',\n",
       " '__число_больше_10000__',\n",
       " 'настроение',\n",
       " 'менеджер',\n",
       " 'статья',\n",
       " 'наверное',\n",
       " 'поставлять',\n",
       " 'быстрый',\n",
       " 'показываться',\n",
       " 'честно',\n",
       " 'идея',\n",
       " 'принцип',\n",
       " 'сколько',\n",
       " 'показывать',\n",
       " 'лично',\n",
       " 'лишь',\n",
       " 'ставить',\n",
       " 'надеяться',\n",
       " 'прямо',\n",
       " 'следующий',\n",
       " 'постоянно',\n",
       " '__число_между_500_и_1000__',\n",
       " 'подобный',\n",
       " 'назад',\n",
       " 'ожидать',\n",
       " 'внутри',\n",
       " 'всякий',\n",
       " 'система',\n",
       " 'около',\n",
       " 'овощ',\n",
       " 'просить',\n",
       " 'однако',\n",
       " 'совет',\n",
       " 'поесть',\n",
       " 'удобно',\n",
       " 'покупать',\n",
       " 'неделя',\n",
       " 'дом',\n",
       " 'сначала',\n",
       " 'прочтение',\n",
       " 'практически',\n",
       " 'вещь',\n",
       " 'стиль',\n",
       " 'туалет',\n",
       " 'факт',\n",
       " 'настоящий',\n",
       " 'смысл',\n",
       " 'искать',\n",
       " 'называть',\n",
       " 'весьма',\n",
       " 'главный',\n",
       " 'играть',\n",
       " 'представлять',\n",
       " 'русский',\n",
       " 'равный',\n",
       " 'размер',\n",
       " 'жаль',\n",
       " 'начало',\n",
       " 'оформление',\n",
       " 'нельзя',\n",
       " 'остальной',\n",
       " 'бармен',\n",
       " 'скидка',\n",
       " 'важный',\n",
       " 'этаж',\n",
       " 'читаться',\n",
       " 'помнить',\n",
       " 'герой',\n",
       " 'тип',\n",
       " 'месяц',\n",
       " 'сотрудник',\n",
       " 'между',\n",
       " 'происходить',\n",
       " 'причем',\n",
       " 'яркий',\n",
       " 'цезарь',\n",
       " 'перевод',\n",
       " 'понятно',\n",
       " 'выглядеть',\n",
       " 'тесто',\n",
       " 'знакомый',\n",
       " 'удаваться',\n",
       " 'будто',\n",
       " 'вызывать',\n",
       " 'мысль',\n",
       " 'окно',\n",
       " 'пирог',\n",
       " 'стейк',\n",
       " 'чек',\n",
       " 'домашний',\n",
       " 'особо',\n",
       " 'съедать',\n",
       " 'всетака',\n",
       " 'теплый',\n",
       " 'формат',\n",
       " 'над',\n",
       " 'ланч',\n",
       " 'оценка',\n",
       " 'качественный',\n",
       " 'успевать',\n",
       " 'кофейня',\n",
       " 'старый',\n",
       " 'прямой',\n",
       " 'приезжать',\n",
       " 'мера',\n",
       " 'холодный',\n",
       " 'мнение',\n",
       " 'акция',\n",
       " 'живой',\n",
       " 'стойка',\n",
       " 'вместо',\n",
       " 'убирать',\n",
       " 'закуска',\n",
       " 'картошка',\n",
       " 'мягкий',\n",
       " 'семья',\n",
       " 'пытаться',\n",
       " 'продукт',\n",
       " 'свободный',\n",
       " 'выпивать',\n",
       " 'супер',\n",
       " 'игра',\n",
       " 'выходной',\n",
       " 'наличие',\n",
       " 'заглядывать',\n",
       " 'садиться',\n",
       " 'имя',\n",
       " 'начинка',\n",
       " 'явно',\n",
       " 'создавать',\n",
       " 'сходить',\n",
       " 'зачем',\n",
       " 'результат',\n",
       " 'обложка',\n",
       " 'белый',\n",
       " 'внимательный',\n",
       " 'касса',\n",
       " 'заниматься',\n",
       " 'утро',\n",
       " 'настолько',\n",
       " 'оценивать',\n",
       " 'занимать',\n",
       " 'желать',\n",
       " 'зато',\n",
       " 'голова',\n",
       " 'решение',\n",
       " 'позволять',\n",
       " 'хватать',\n",
       " 'мама',\n",
       " 'сладкий',\n",
       " 'опыт',\n",
       " 'руб',\n",
       " 'кусочек',\n",
       " 'лицо',\n",
       " 'читатель',\n",
       " 'родитель',\n",
       " 'понятный',\n",
       " 'достойный',\n",
       " 'держать',\n",
       " 'описание',\n",
       " 'ехать',\n",
       " 'код',\n",
       " 'сюжет',\n",
       " 'впервые',\n",
       " 'перекусить',\n",
       " 'рыба',\n",
       " 'недавно',\n",
       " 'ошибка',\n",
       " 'мимо',\n",
       " 'чтение',\n",
       " 'мужчина',\n",
       " 'девочка',\n",
       " 'дорогой',\n",
       " 'приводить',\n",
       " 'столько',\n",
       " 'сей',\n",
       " 'телефон',\n",
       " 'молодец',\n",
       " 'помещение',\n",
       " 'торт',\n",
       " 'порядок',\n",
       " 'администратор',\n",
       " 'напоминать',\n",
       " 'остальное',\n",
       " '__число_между_50_и_100__',\n",
       " 'собираться',\n",
       " 'сложно',\n",
       " 'полагать',\n",
       " '__число_между_2100_и_5000__',\n",
       " 'несмотря',\n",
       " 'фирменный',\n",
       " 'красиво',\n",
       " 'повод',\n",
       " 'хлеб',\n",
       " 'масло',\n",
       " 'сила',\n",
       " 'претензия',\n",
       " 'половина',\n",
       " '__число_между_1000_и_1500__',\n",
       " 'легкий',\n",
       " 'таки',\n",
       " 'улица',\n",
       " 'твердый',\n",
       " 'заставлять',\n",
       " 'объяснять',\n",
       " 'ужасный',\n",
       " 'москва',\n",
       " 'пожалеть',\n",
       " 'похожий',\n",
       " 'обращать',\n",
       " 'необычный',\n",
       " 'веранда',\n",
       " 'покушать',\n",
       " 'заранее',\n",
       " 'реально',\n",
       " 'образ',\n",
       " 'странный',\n",
       " 'завтрак',\n",
       " 'правило',\n",
       " 'сын',\n",
       " 'видно',\n",
       " 'современный',\n",
       " 'шашлык',\n",
       " 'положительный',\n",
       " 'кушать',\n",
       " 'женщина',\n",
       " 'процесс',\n",
       " 'путь',\n",
       " 'пятница',\n",
       " 'высоко',\n",
       " 'великолепный',\n",
       " 'ужин',\n",
       " 'причина',\n",
       " 'задача',\n",
       " 'проект',\n",
       " 'побывать',\n",
       " 'рецепт',\n",
       " 'сказка',\n",
       " 'точка',\n",
       " 'располагать',\n",
       " 'материал',\n",
       " 'содержание',\n",
       " 'ладно',\n",
       " 'начинаться',\n",
       " 'куча',\n",
       " 'классный',\n",
       " 'алкоголь',\n",
       " 'гриб',\n",
       " 'стена',\n",
       " 'чувство',\n",
       " 'развитие',\n",
       " 'отдельно',\n",
       " 'ночь',\n",
       " 'высота',\n",
       " 'глава',\n",
       " 'никак',\n",
       " 'отдавать',\n",
       " 'указывать',\n",
       " 'нежный',\n",
       " 'лишний',\n",
       " 'коллега',\n",
       " 'примерно',\n",
       " 'произведение',\n",
       " 'сложный',\n",
       " 'цель',\n",
       " 'собственный',\n",
       " 'чисто',\n",
       " 'поздно',\n",
       " 'подумать',\n",
       " 'целый',\n",
       " 'острый',\n",
       " 'проверять',\n",
       " 'возникать',\n",
       " 'ценник',\n",
       " 'дорого',\n",
       " 'выпечка',\n",
       " 'встреча',\n",
       " 'доступный',\n",
       " 'предыдущий',\n",
       " 'невозможно',\n",
       " 'везде',\n",
       " 'отсутствие',\n",
       " 'страна',\n",
       " 'комментарий',\n",
       " 'чудесный',\n",
       " 'число',\n",
       " 'чистый',\n",
       " 'крутой',\n",
       " 'ибо',\n",
       " 'испортить',\n",
       " 'лимонад',\n",
       " 'крайне',\n",
       " 'запах',\n",
       " 'правильно',\n",
       " 'задание',\n",
       " 'праздник',\n",
       " 'мелочь',\n",
       " 'план',\n",
       " 'посуда',\n",
       " 'летний',\n",
       " 'близкий',\n",
       " 'разочаровывать',\n",
       " 'оформлять',\n",
       " 'соответствовать',\n",
       " 'слышать',\n",
       " 'барный',\n",
       " 'потрясать',\n",
       " 'третий',\n",
       " 'личный',\n",
       " 'разнообразный',\n",
       " 'лапша',\n",
       " 'однозначно',\n",
       " 'касаться',\n",
       " 'фотография',\n",
       " 'особый',\n",
       " 'цвет',\n",
       " 'относиться',\n",
       " 'постоянный',\n",
       " 'сухой',\n",
       " 'знание',\n",
       " 'разбираться',\n",
       " 'программа',\n",
       " 'чтоб',\n",
       " 'номер',\n",
       " 'устраивать',\n",
       " 'рад',\n",
       " 'почитать',\n",
       " 'черный',\n",
       " 'стакан',\n",
       " 'свет',\n",
       " 'вывод',\n",
       " 'больший',\n",
       " 'ради',\n",
       " 'большинство',\n",
       " 'форма',\n",
       " 'тонкий',\n",
       " 'голодный',\n",
       " 'может',\n",
       " 'уметь',\n",
       " 'включать',\n",
       " 'учитывать',\n",
       " 'собирать',\n",
       " 'магазин',\n",
       " 'куриный',\n",
       " 'прекрасно',\n",
       " 'бокал',\n",
       " 'фильм',\n",
       " 'звезда',\n",
       " 'сочный',\n",
       " 'капучино',\n",
       " 'красный',\n",
       " 'рис',\n",
       " 'должно',\n",
       " 'шикарный',\n",
       " 'суть',\n",
       " 'филиал',\n",
       " 'пустой',\n",
       " 'отдыхать',\n",
       " 'спокойно',\n",
       " 'далее',\n",
       " 'приемлемый',\n",
       " 'нести',\n",
       " 'привозить',\n",
       " 'курить',\n",
       " 'взрослый',\n",
       " 'пол',\n",
       " 'картофель',\n",
       " 'прошлый',\n",
       " 'выполнять',\n",
       " 'россия',\n",
       " 'пользоваться',\n",
       " 'долгий',\n",
       " 'лосось',\n",
       " 'пожалуй',\n",
       " 'правильный',\n",
       " 'помощь',\n",
       " 'приготовление',\n",
       " 'открытие',\n",
       " 'уточнять',\n",
       " 'сырный',\n",
       " 'рисунок',\n",
       " 'говядина',\n",
       " 'открываться',\n",
       " 'забирать',\n",
       " 'кусок',\n",
       " 'рассматривать',\n",
       " 'пять',\n",
       " 'дома',\n",
       " 'креветка',\n",
       " 'дверь',\n",
       " 'труд',\n",
       " 'какието',\n",
       " 'стоимость',\n",
       " 'гораздо',\n",
       " 'лист',\n",
       " 'заканчиваться',\n",
       " 'эмоция',\n",
       " 'крупный',\n",
       " 'посоветовать',\n",
       " 'просьба',\n",
       " 'попадаться',\n",
       " 'балл',\n",
       " 'грязный',\n",
       " 'идеальный',\n",
       " 'стараться',\n",
       " 'улыбка',\n",
       " 'редко',\n",
       " 'выход',\n",
       " 'составлять',\n",
       " 'лук',\n",
       " 'соседний',\n",
       " 'событие',\n",
       " 'низкий',\n",
       " 'суббота',\n",
       " 'рабочий',\n",
       " 'приличный',\n",
       " 'возраст',\n",
       " 'почемуто',\n",
       " 'нога',\n",
       " 'многое',\n",
       " 'случайно',\n",
       " 'продолжать',\n",
       " 'здорово',\n",
       " 'кажется',\n",
       " 'предложение',\n",
       " 'малыш',\n",
       " 'успех',\n",
       " 'различный',\n",
       " 'интерес',\n",
       " 'дочка',\n",
       " 'известный',\n",
       " 'пусть',\n",
       " 'зона',\n",
       " 'двое',\n",
       " 'буквально',\n",
       " 'предупреждать',\n",
       " 'реальный',\n",
       " 'котлета',\n",
       " 'плотный',\n",
       " 'оригинальный',\n",
       " 'отказываться',\n",
       " 'близко',\n",
       " 'морс',\n",
       " 'руководство',\n",
       " 'входить',\n",
       " 'диван',\n",
       " 'сумма',\n",
       " 'значит',\n",
       " 'хватить',\n",
       " 'комната',\n",
       " 'речь',\n",
       " 'безумно',\n",
       " 'очередной',\n",
       " 'расположение',\n",
       " 'пельмень',\n",
       " 'захотеться',\n",
       " 'покупка',\n",
       " 'машина',\n",
       " 'дешевый',\n",
       " 'собственно',\n",
       " 'множество',\n",
       " 'ассортимент',\n",
       " 'сытный',\n",
       " 'район',\n",
       " 'екатеринбург',\n",
       " 'иначе',\n",
       " 'подход',\n",
       " 'недостаток',\n",
       " 'детство',\n",
       " 'изучать',\n",
       " 'интернет',\n",
       " 'менять',\n",
       " 'булочка',\n",
       " 'сравнение',\n",
       " 'итальянский',\n",
       " 'позиция',\n",
       " 'приложение',\n",
       " 'шрифт',\n",
       " 'возвращаться',\n",
       " 'счастие',\n",
       " 'минимум',\n",
       " 'объем',\n",
       " 'действие',\n",
       " 'веселый',\n",
       " 'согласный',\n",
       " 'чувствовать',\n",
       " 'забегать',\n",
       " 'обожать',\n",
       " 'отличаться',\n",
       " 'рассказ',\n",
       " 'набор',\n",
       " 'конкретный',\n",
       " 'сравнивать',\n",
       " 'вести',\n",
       " 'встречаться',\n",
       " 'мешать',\n",
       " 'приобретать',\n",
       " 'состав',\n",
       " 'память',\n",
       " 'иной',\n",
       " 'ничего',\n",
       " 'поскольку',\n",
       " 'обнаруживать',\n",
       " 'адекватный',\n",
       " 'способ',\n",
       " 'улыбаться',\n",
       " 'литература',\n",
       " 'рекомендация',\n",
       " 'данные',\n",
       " 'класс',\n",
       " 'случаться',\n",
       " 'местный',\n",
       " 'благодаря',\n",
       " 'соглашаться',\n",
       " 'деталь',\n",
       " 'пожалуйста',\n",
       " 'классический',\n",
       " 'состояние',\n",
       " 'практика',\n",
       " 'мелкий',\n",
       " 'увы',\n",
       " 'группа',\n",
       " 'гриль',\n",
       " 'домой',\n",
       " 'складываться',\n",
       " 'поиск',\n",
       " 'сок',\n",
       " 'сильный',\n",
       " 'подаваться',\n",
       " 'везти',\n",
       " 'впечатлить',\n",
       " 'мясной',\n",
       " 'английский',\n",
       " 'вспомнить',\n",
       " 'наконец',\n",
       " 'уверенный',\n",
       " 'закрывать',\n",
       " 'пообедать',\n",
       " 'лето',\n",
       " 'дизайн',\n",
       " 'неприятный',\n",
       " 'подробно',\n",
       " 'стул',\n",
       " 'лежать',\n",
       " 'условие',\n",
       " 'местечко',\n",
       " 'затем',\n",
       " 'жена',\n",
       " 'хостес',\n",
       " 'красочный',\n",
       " 'бог',\n",
       " 'странно',\n",
       " 'зеленый',\n",
       " 'общаться',\n",
       " 'ложка',\n",
       " 'называться',\n",
       " 'насколько',\n",
       " 'список',\n",
       " 'общение',\n",
       " 'изменять',\n",
       " 'ненавязчивый',\n",
       " 'снимать',\n",
       " 'многие',\n",
       " 'наедаться',\n",
       " 'дешево',\n",
       " 'свинина',\n",
       " 'наслаждаться',\n",
       " 'заменять',\n",
       " 'скорость',\n",
       " 'версия',\n",
       " 'придумывать',\n",
       " 'бонус',\n",
       " 'прощать',\n",
       " 'понимание',\n",
       " 'заявлять',\n",
       " 'кассир',\n",
       " 'обещать',\n",
       " 'сочетание',\n",
       " 'темный',\n",
       " 'готовиться',\n",
       " 'доброжелательный',\n",
       " 'мороженое',\n",
       " 'ссылка',\n",
       " 'задумываться',\n",
       " 'песня',\n",
       " 'тем',\n",
       " 'позвонить',\n",
       " 'перечитывать',\n",
       " 'следовать',\n",
       " 'команда',\n",
       " 'связь',\n",
       " 'вообщий',\n",
       " 'пончик',\n",
       " 'штука',\n",
       " 'изменяться',\n",
       " 'ингредиент',\n",
       " 'дорога',\n",
       " 'течение',\n",
       " 'специально',\n",
       " 'сахар',\n",
       " 'вокруг',\n",
       " 'реклама',\n",
       " 'чувствоваться',\n",
       " 'подождать',\n",
       " 'гардероб',\n",
       " 'разговор',\n",
       " 'основа',\n",
       " 'крайний',\n",
       " 'молоко',\n",
       " 'блин',\n",
       " 'исправлять',\n",
       " 'персонаж',\n",
       " 'ошибаться',\n",
       " 'столовая',\n",
       " 'намного',\n",
       " 'улыбчивый',\n",
       " 'замечание',\n",
       " 'метод',\n",
       " 'бесплатный',\n",
       " 'пользователь',\n",
       " 'выдавать',\n",
       " 'фраза',\n",
       " 'дыхание',\n",
       " 'жирный',\n",
       " 'запоминать',\n",
       " 'шоколад',\n",
       " 'доходить',\n",
       " 'паб',\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "2018-02-15 22:06:40,195 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('официантка', 0.9459431171417236),\n",
       " ('девушкаофициант', 0.7950291633605957),\n",
       " ('персонал', 0.7920031547546387),\n",
       " ('администратор', 0.7191694974899292),\n",
       " ('девушка', 0.7173543572425842),\n",
       " ('кассир', 0.7008011341094971),\n",
       " ('кальянщик', 0.6782796382904053),\n",
       " ('девушкаофициантка', 0.654279351234436),\n",
       " ('хостес', 0.6517984867095947),\n",
       " ('офик', 0.651033878326416)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('официант')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.16490519, -2.39631724,  1.22702217, -0.4833999 , -1.81730068,\n",
       "       -0.48772752,  0.89475888, -0.2036234 ,  1.78867042, -0.47792315,\n",
       "       -1.94477391,  0.28253135, -2.86050558, -1.88632739, -2.79638648,\n",
       "        1.87157404,  2.06843829, -0.04652323,  1.88178909,  1.03721488,\n",
       "        2.2300396 ,  1.15912724, -2.13789368,  0.3728328 ,  0.37598792,\n",
       "       -0.36440837,  2.07403731, -0.47243625, -0.02244153,  1.27159321,\n",
       "       -2.44426537, -0.50231838,  2.15738416,  0.671911  , -0.42188048,\n",
       "       -2.22126532,  0.25318474, -1.55090678,  2.38419366, -0.72404426,\n",
       "       -1.10256445, -0.28712273,  4.61564064, -0.58936644, -0.78231442,\n",
       "        0.74315983, -0.40295851, -0.53364909,  2.00119185,  1.4031204 ,\n",
       "        0.84262437,  0.16767573,  1.99934852,  1.01910639, -2.2733047 ,\n",
       "       -1.41535187,  0.84479833, -3.5623436 ,  1.02344   ,  0.47774908,\n",
       "       -0.9200446 ,  0.1271165 ,  0.08192538, -0.80192125, -0.2261727 ,\n",
       "       -2.33092022, -2.01634717,  3.48501158,  2.16095686, -2.39072537,\n",
       "       -0.56087989, -3.62946105,  0.3432337 ,  1.13856685, -0.0354965 ,\n",
       "       -1.01865697,  4.68168974, -0.79879922, -1.38670039, -1.47410047,\n",
       "        1.46335876, -0.11219192, -3.08924341, -0.67080337,  1.57089031,\n",
       "        0.82789451,  0.17678455,  1.6628356 ,  1.64672732, -0.60566837,\n",
       "       -1.69300866,  0.68941754,  1.45721126, -1.11023438,  0.07267392,\n",
       "        2.03814745, -1.28137589,  1.58733559, -3.50445557,  0.17570537], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.word_vec('официант')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(vocabulary=model.wv.index2word)\n",
    "X = tfidf.fit_transform((' '.join(i) for i in sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(237591, 41046)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_source = tfidf.transform((' '.join(i) for i in train_sentences))\n",
    "X_test_source = tfidf.transform((' '.join(i) for i in test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41046, 100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.syn0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154371, 41046)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_source.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83220, 41046)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_source.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v = X_train_source.dot(model.wv.syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154371, 100)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_w2v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import  DecisionTreeClassifier\n",
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.metrics import  confusion_matrix, classification_report\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_w2v = []\n",
    "Y_train_w2v_condition = []\n",
    "with open('./big_train.csv','r') as f:\n",
    "    f.readline()\n",
    "    for line in f:\n",
    "        ratingCount = line.strip().split(',')[5]\n",
    "        if ratingCount != 'n/a':\n",
    "            Y_train_w2v.append(int(ratingCount))\n",
    "            Y_train_w2v_condition.append(True)\n",
    "        else:\n",
    "            Y_train_w2v_condition.append(False)\n",
    "Y_train_w2v = np.array(Y_train_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((84070,), 154371)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_w2v.shape, len(Y_train_w2v_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154371, 41046)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_source.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "_X_train_source = X_train_source[np.array(Y_train_w2v_condition)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84070, 41046)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_X_train_source.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v = X_train_source.dot(model.wv.syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "_X_train_w2v = X_train_w2v[np.array(Y_train_w2v_condition)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84070, 100)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_X_train_w2v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,  X_test, Y_train, Y_test = train_test_split(_X_train_w2v, Y_train_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=12,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=12, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=12, min_samples_leaf=12)\n",
    "dt.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.36      0.37      0.37      1495\n",
      "          2       0.28      0.16      0.20      1449\n",
      "          3       0.24      0.18      0.21      1974\n",
      "          4       0.27      0.13      0.18      3188\n",
      "          5       0.74      0.91      0.82     12912\n",
      "\n",
      "avg / total       0.57      0.63      0.59     21018\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=Y_test, y_pred=Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=1.5, solver='newton-cg')\n",
    "logreg.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1     0.4811    0.5191    0.4994      1495\n",
      "          2     0.3282    0.0594    0.1005      1449\n",
      "          3     0.3272    0.1444    0.2004      1974\n",
      "          4     0.3631    0.1785    0.2393      3188\n",
      "          5     0.7451    0.9640    0.8405     12912\n",
      "\n",
      "avg / total     0.6004    0.6739    0.6139     21018\n",
      "\n",
      "[[  776    78   135    52   454]\n",
      " [  404    86   237   199   523]\n",
      " [  237    61   285   446   945]\n",
      " [  111    23   149   569  2336]\n",
      " [   85    14    65   301 12447]]\n"
     ]
    }
   ],
   "source": [
    "Y_pred = logreg.predict(X_test)\n",
    "print(classification_report(y_true=Y_test, y_pred=Y_pred, digits=4))\n",
    "print(confusion_matrix(y_true=Y_test, y_pred=Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_w2v = X_test_source.dot(model.wv.syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83220, 100)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_w2v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_target = logreg.predict(X_test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   46.1s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:  9.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=1,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(max_depth=7, n_estimators=2000, n_jobs=-1, verbose=1)\n",
    "rf_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn= MLPRegressor(hidden_layer_sizes=(1000), activation='relu', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.59354262\n",
      "Iteration 2, loss = 0.76177608\n",
      "Iteration 3, loss = 0.74269981\n",
      "Iteration 4, loss = 0.73315039\n",
      "Iteration 5, loss = 0.72943118\n",
      "Iteration 6, loss = 0.72822439\n",
      "Iteration 7, loss = 0.72810972\n",
      "Iteration 8, loss = 0.72793381\n",
      "Iteration 9, loss = 0.72777146\n",
      "Iteration 10, loss = 0.72808187\n",
      "Iteration 11, loss = 0.72862369\n",
      "Iteration 12, loss = 0.72829609\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=1000, learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = nn.predict(X_test)\n",
    "# print(classification_report(y_true=Y_test, y_pred=Y_pred))\n",
    "# print(confusion_matrix(y_true=Y_test, y_pred=Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_target = nn.predict(X_test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(\n",
    "    dtype=tf.float32,\n",
    "    shape=[None, 100]\n",
    ")\n",
    "\n",
    "y = tf.placeholder(\n",
    "    dtype=tf.float32,\n",
    "    shape=[None, 5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = tf.layers.Dense(\n",
    "    units=128,\n",
    "    activation=tf.nn.elu\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tf.layers.Dense(units=4, activation=None)(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = tf.nn.softmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-25 15:22:54,394 : WARNING : From <ipython-input-56-12d56715c841>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_entropy_loss = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=output,\n",
    "    labels=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(cross_entropy_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "_Y_train = Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63052,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "_Y_train = _Y_train.reshape(63052,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 5, ..., 5, 5, 5])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-174-e56bbdd05ccb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_Y_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Y_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     __Y.append(\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     )\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "__Y = []\n",
    "\n",
    "for i in range(_Y_train.size):\n",
    "    if i > 20:\n",
    "        break\n",
    "    test = [0 for j in range(5)]\n",
    "    test[_Y_train[i] - 1] = _Y_train[i]\n",
    "    __Y.append([i, np.array(test)])\n",
    "\n",
    "print(__Y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "__Y = []\n",
    "\n",
    "\n",
    "for i in range(_Y_train.size):\n",
    "    __Y.append([i, _Y_train[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "__Y = np.array(__Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 5, ..., 5, 5, 5])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__Y[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_data(X=X_train, Y=_Y_train, batch_size=100) :\n",
    "    batch_x = []\n",
    "    batch_y = []\n",
    "    for _x, _y in zip(X, Y):\n",
    "        batch_x.append(_x)\n",
    "        batch_y.append(_y)\n",
    "        if len(batch_x) == batch_size:\n",
    "            yield np.array(batch_x), np.array(batch_y)\n",
    "            batch_x = []\n",
    "            batch_y = []\n",
    "    yield np.array(batch_x), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (100,) for Tensor 'Placeholder_1:0', which has shape '(?, 5)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-86e95e69032f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m             feed_dict = {\n\u001b[1;32m     11\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             }\n\u001b[1;32m     14\u001b[0m         )\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1105\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (100,) for Tensor 'Placeholder_1:0', which has shape '(?, 5)'"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for _tick, (_x, _y) in enumerate(iter_data()):\n",
    "#         if _tick > 3:\n",
    "#             break\n",
    "#         print(_x)\n",
    "        _, _loss, _softmax = sess.run(\n",
    "            [train_op, loss, softmax],\n",
    "            feed_dict = {\n",
    "                x: _x,\n",
    "                y: _y\n",
    "            }\n",
    "        )\n",
    "        print(loss)\n",
    "        \n",
    "        if not _tick % 50:\n",
    "            print(_softmax[0], _y[0])\n",
    "            saver.save(sess=sess, save_path='./test-model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission.csv','w') as sol:\n",
    "    with open('./rating_test_without_rating.csv', 'r') as f:\n",
    "        sol.write('_id,rating\\n')\n",
    "        f.readline()\n",
    "        for (line, label) in zip(f, Y_target):\n",
    "            data = line.split(',')\n",
    "            sol.write('%s,%s\\n' % (data[0], label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
